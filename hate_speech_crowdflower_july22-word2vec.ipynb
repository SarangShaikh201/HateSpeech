{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQKHRu7mN2My"
   },
   "source": [
    "<h3>Looking At Hate Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xNQaWvMN2M3"
   },
   "source": [
    "All the beauty of the internet age comes with its fair share of ugliness as well. In recent months, this dark side of the web that lives on Twitter has been in the spotlight as a component of the wider deluge of pieces on that company's future. As great as it is as a repository of conversation on almost every topic, it's the bad eggs that seem to define Twitter recently. As seen from Microsoft's ill-fated AI experiment on Twitter, hate speech is a frequent vehicle of choice in the platform's darker flight paths. \n",
    "\n",
    "From a Natural Language Processing perspective, identifying hate speech is an intriguing problem as the notion of what does or doesn't qualify - for better or for worse - can vary. Firstly, though, one has to get some data - some labeled data to be more specific. You could go the route of collecting and then labeling it yourself, but that will be: 1) quite time consuming and 2) incredibly biased towards your own perspective. How then to be time efficient and less biased?\n",
    "\n",
    "The answer is to crowd source it, but even that is made trivial by the fact that CrowdFlower already has such a dataset available for [free](http://www.crowdflower.com/data-for-everyone/), one of which concerns hate speech on Twitter. Here's the description:\n",
    "\n",
    ">Hate speech identification\n",
    "\n",
    ">Contributors viewed short text and identified if it a) contained hate speech, b) was offensive but without hate speech, or c) >was not offensive at all. Contains nearly 15K rows with three contributor judgments per text string.\n",
    "\n",
    "With that obstacle avoided now all that’s left is to build a model to identify hate speech. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yjQMeaSN2M7"
   },
   "source": [
    "<h3> Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "oopHw19ON2M_",
    "outputId": "2888257f-810d-4ba5-f1b1-4475b239bedf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.core._multiarray_umath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14509 data points.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>does_this_tweet_contain_hate_speech</th>\n",
       "      <th>does_this_tweet_contain_hate_speech:confidence</th>\n",
       "      <th>_created_at</th>\n",
       "      <th>orig__golden</th>\n",
       "      <th>orig__last_judgment_at</th>\n",
       "      <th>orig__trusted_judgments</th>\n",
       "      <th>orig__unit_id</th>\n",
       "      <th>orig__unit_state</th>\n",
       "      <th>_updated_at</th>\n",
       "      <th>orig_does_this_tweet_contain_hate_speech</th>\n",
       "      <th>does_this_tweet_contain_hate_speech_gold</th>\n",
       "      <th>does_this_tweet_contain_hate_speech_gold_reason</th>\n",
       "      <th>does_this_tweet_contain_hate_speechconfidence</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853718217</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.6013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>615561535.0</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666196e+09</td>\n",
       "      <td>Warning: penny boards will make you a faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>853718218</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>615561723.0</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.295121e+08</td>\n",
       "      <td>Fuck dykes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>853718219</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>615562039.0</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.956238e+08</td>\n",
       "      <td>@sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853718220</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>615562068.0</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.975147e+08</td>\n",
       "      <td>\"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>853718221</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>615562488.0</td>\n",
       "      <td>golden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>The tweet contains hate speech\\nThe tweet uses...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.889236e+08</td>\n",
       "      <td>@Zhugstubble You heard me bitch but any way I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  853718217     True      golden                  86               NaN   \n",
       "1  853718218     True      golden                  92               NaN   \n",
       "2  853718219     True      golden                  86               NaN   \n",
       "3  853718220     True      golden                  98               NaN   \n",
       "4  853718221     True      golden                  88               NaN   \n",
       "\n",
       "                 does_this_tweet_contain_hate_speech  \\\n",
       "0  The tweet uses offensive language but not hate...   \n",
       "1                     The tweet contains hate speech   \n",
       "2                     The tweet contains hate speech   \n",
       "3                     The tweet contains hate speech   \n",
       "4  The tweet uses offensive language but not hate...   \n",
       "\n",
       "   does_this_tweet_contain_hate_speech:confidence  _created_at orig__golden  \\\n",
       "0                                          0.6013          NaN         True   \n",
       "1                                          0.7227          NaN         True   \n",
       "2                                          0.5229          NaN         True   \n",
       "3                                          0.5184          NaN         True   \n",
       "4                                          0.5185          NaN         True   \n",
       "\n",
       "   orig__last_judgment_at  orig__trusted_judgments  orig__unit_id  \\\n",
       "0                     NaN                      0.0    615561535.0   \n",
       "1                     NaN                      0.0    615561723.0   \n",
       "2                     NaN                      0.0    615562039.0   \n",
       "3                     NaN                      0.0    615562068.0   \n",
       "4                     NaN                      0.0    615562488.0   \n",
       "\n",
       "  orig__unit_state  _updated_at orig_does_this_tweet_contain_hate_speech  \\\n",
       "0           golden          NaN           The tweet contains hate speech   \n",
       "1           golden          NaN           The tweet contains hate speech   \n",
       "2           golden          NaN           The tweet contains hate speech   \n",
       "3           golden          NaN           The tweet contains hate speech   \n",
       "4           golden          NaN           The tweet contains hate speech   \n",
       "\n",
       "            does_this_tweet_contain_hate_speech_gold  \\\n",
       "0  The tweet contains hate speech\\nThe tweet uses...   \n",
       "1  The tweet contains hate speech\\nThe tweet uses...   \n",
       "2  The tweet contains hate speech\\nThe tweet uses...   \n",
       "3  The tweet contains hate speech\\nThe tweet uses...   \n",
       "4  The tweet contains hate speech\\nThe tweet uses...   \n",
       "\n",
       "   does_this_tweet_contain_hate_speech_gold_reason  \\\n",
       "0                                              NaN   \n",
       "1                                              NaN   \n",
       "2                                              NaN   \n",
       "3                                              NaN   \n",
       "4                                              NaN   \n",
       "\n",
       "   does_this_tweet_contain_hate_speechconfidence      tweet_id  \\\n",
       "0                                            1.0  1.666196e+09   \n",
       "1                                            1.0  4.295121e+08   \n",
       "2                                            1.0  3.956238e+08   \n",
       "3                                            1.0  4.975147e+08   \n",
       "4                                            1.0  5.889236e+08   \n",
       "\n",
       "                                          tweet_text  \n",
       "0       Warning: penny boards will make you a faggot  \n",
       "1                                         Fuck dykes  \n",
       "2  @sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...  \n",
       "3  \"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...  \n",
       "4  @Zhugstubble You heard me bitch but any way I'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "hate_speech = pd.read_csv('twitter-hate-speech-classifier-DFE-a845520.csv', \n",
    "                          encoding = 'iso-8859-1')\n",
    "print('There are', len(hate_speech), 'data points.')\n",
    "hate_speech.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lic5izYGN2NL"
   },
   "source": [
    "There are exactly 14,509 rows in this dataset and it looks very messy. Unfortunately a code book wasn't available, but some of the columns are easy enough to understand. Let's get a grasp on the missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "40w1eHTJN2NP",
    "outputId": "9e241572-2f49-41ba-e2f2-48487efe1da2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unit_id                                               0\n",
       "_golden                                                0\n",
       "_unit_state                                            0\n",
       "_trusted_judgments                                     0\n",
       "_last_judgment_at                                     67\n",
       "does_this_tweet_contain_hate_speech                    0\n",
       "does_this_tweet_contain_hate_speech:confidence         0\n",
       "_created_at                                        14509\n",
       "orig__golden                                       14442\n",
       "orig__last_judgment_at                             14509\n",
       "orig__trusted_judgments                            14442\n",
       "orig__unit_id                                      14442\n",
       "orig__unit_state                                   14442\n",
       "_updated_at                                        14509\n",
       "orig_does_this_tweet_contain_hate_speech           14442\n",
       "does_this_tweet_contain_hate_speech_gold           14442\n",
       "does_this_tweet_contain_hate_speech_gold_reason    14509\n",
       "does_this_tweet_contain_hate_speechconfidence      14442\n",
       "tweet_id                                               0\n",
       "tweet_text                                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate_speech) - hate_speech.count() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1V3NVCDN2NZ"
   },
   "source": [
    "There's a lot of missing data, but luckily the (seemingly) most relevant columns are all complete. I'll keep the tweets, whether or not it contains hate speech, and the level of confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "zA6lWYkjN2Nc",
    "outputId": "9299c55c-496e-47c5-9f97-359f70cd4e39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 _unit_id\n",
      "1 _golden\n",
      "2 _unit_state\n",
      "3 _trusted_judgments\n",
      "4 _last_judgment_at\n",
      "5 does_this_tweet_contain_hate_speech\n",
      "6 does_this_tweet_contain_hate_speech:confidence\n",
      "7 _created_at\n",
      "8 orig__golden\n",
      "9 orig__last_judgment_at\n",
      "10 orig__trusted_judgments\n",
      "11 orig__unit_id\n",
      "12 orig__unit_state\n",
      "13 _updated_at\n",
      "14 orig_does_this_tweet_contain_hate_speech\n",
      "15 does_this_tweet_contain_hate_speech_gold\n",
      "16 does_this_tweet_contain_hate_speech_gold_reason\n",
      "17 does_this_tweet_contain_hate_speechconfidence\n",
      "18 tweet_id\n",
      "19 tweet_text\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(hate_speech.columns):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ApBjp-GsN2No",
    "outputId": "142eb5d9-ea48-47d4-c700-79427c2b852a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warning: penny boards will make you a faggot</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.6013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuck dykes</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.7227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Zhugstubble You heard me bitch but any way I'...</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0       Warning: penny boards will make you a faggot   \n",
       "1                                         Fuck dykes   \n",
       "2  @sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...   \n",
       "3  \"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...   \n",
       "4  @Zhugstubble You heard me bitch but any way I'...   \n",
       "\n",
       "                                             Verdict  Confidence  \n",
       "0  The tweet uses offensive language but not hate...      0.6013  \n",
       "1                     The tweet contains hate speech      0.7227  \n",
       "2                     The tweet contains hate speech      0.5229  \n",
       "3                     The tweet contains hate speech      0.5184  \n",
       "4  The tweet uses offensive language but not hate...      0.5185  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_subset = hate_speech.iloc[:, [19, 5, 6]]\n",
    "hate_speech_subset.columns = ['Tweets', 'Verdict', 'Confidence']\n",
    "hate_speech_subset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Wt2_AvCN2Nz"
   },
   "source": [
    "The Verdict column is the target and has three labels which could be categorical or ordinal depending on how you want to interpret it. For ease of use in different algorithms it's best to encode the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZPhvfgT_N2N2",
    "outputId": "519fc327-3fa6-4b06-ee00-ec7eebb826e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Verdict</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Numeric_Verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warning: penny boards will make you a faggot</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.6013</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fuck dykes</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.7227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...</td>\n",
       "      <td>The tweet contains hate speech</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Zhugstubble You heard me bitch but any way I'...</td>\n",
       "      <td>The tweet uses offensive language but not hate...</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0       Warning: penny boards will make you a faggot   \n",
       "1                                         Fuck dykes   \n",
       "2  @sizzurp__ @ILIKECATS74 @yoPapi_chulo @brandon...   \n",
       "3  \"@jayswaggkillah: \"@JacklynAnnn: @jayswaggkill...   \n",
       "4  @Zhugstubble You heard me bitch but any way I'...   \n",
       "\n",
       "                                             Verdict  Confidence  \\\n",
       "0  The tweet uses offensive language but not hate...      0.6013   \n",
       "1                     The tweet contains hate speech      0.7227   \n",
       "2                     The tweet contains hate speech      0.5229   \n",
       "3                     The tweet contains hate speech      0.5184   \n",
       "4  The tweet uses offensive language but not hate...      0.5185   \n",
       "\n",
       "   Numeric_Verdict  \n",
       "0                2  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(list(hate_speech_subset.Verdict.unique()))\n",
    "hate_speech_subset['Numeric_Verdict'] = le.transform(list(hate_speech_subset.Verdict.values))\n",
    "hate_speech_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bBfYq8ydN2N9"
   },
   "source": [
    "Now I have numbers representing each label, but it's easy to see the number-label relationship. (As if the snapshot above didn't make it clear.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "AmKFOvWrN2OA",
    "outputId": "0a344fad-8705-4f78-83dd-dd5257d154e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : The tweet contains hate speech\n",
      "1 : The tweet is not offensive\n",
      "2 : The tweet uses offensive language but not hate speech\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(le.classes_):\n",
    "    print(i, ':', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4p0zOxL4N2OH"
   },
   "source": [
    "Using Confidence as a variable would be straightforward but processing has to be done on the Tweets to use them as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9WeYmjjN2OJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sarang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sarang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def processTweet(tweet):\n",
    "\n",
    "    tweet = tweet.lower()    \n",
    "    #Remove urls\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '', tweet)    \n",
    "    #Remove usernames\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)    \n",
    "    #Remove white space\n",
    "    tweet = tweet.strip()    \n",
    "    #Remove hashtags\n",
    "    tweet = re.sub(r'#([^\\s]+)', '', tweet)   \n",
    "    #Remove stopwords\n",
    "    tweet = \" \".join([word for word in tweet.split(' ') if word not in stopwords.words('english')])\n",
    "    #Remove punctuation\n",
    "    tweet = \"\".join(l for l in tweet if l not in string.punctuation)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "hate_speech_subset['Tweets'] = hate_speech_subset['Tweets'].map(lambda x: processTweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         warning penny boards make faggot\n",
      "1                                               fuck dykes\n",
      "2                 least dont look like jefree starr faggot\n",
      "3                                fag jackie jealous neeeee\n",
      "4        heard bitch way im back th texas wtf u talking...\n",
      "5        dirty terrorist religion fucking joke go aroun...\n",
      "6                                rt   looking like faggots\n",
      "7        well thought knew actually rt  man yall tell d...\n",
      "8                                         know joke faggot\n",
      "9        im tired people saying look like brother amp c...\n",
      "10        yeah cuz 8 million people faggot ass   jewsgt...\n",
      "11            word use roids stupid hypocrite lying faggot\n",
      "12                                       hate faggots like\n",
      "13       shut nigger whore hope u get raped one animals...\n",
      "14       fuck nigger sheboon hope r strung like niggers...\n",
      "15       used tie ends niggers legs 2 different horses ...\n",
      "16       good night fags fagettes thats female version ...\n",
      "17       cant stand crybaby ass nigga gonna act like bi...\n",
      "18                                             rt   nigger\n",
      "19                    ill fuck til love faggot  mike tyson\n",
      "20       whats problem u know jews control niggers read...\n",
      "21                               fucking hate niggers bruh\n",
      "22          rt  species birds known hold funerals deceased\n",
      "23       remember draft prom night dress zip bawling ey...\n",
      "24       damn eli thats ruff im even gonna trash talk o...\n",
      "25       also happy armistice day anachronists\\n\\n hun ...\n",
      "26       friend suggested dress fairy halloween party w...\n",
      "27       rt  apparently  means  anyone else always thou...\n",
      "28       suspended day random lag spikes force close cl...\n",
      "29        w moxy big comeback again major penalty kille...\n",
      "                               ...                        \n",
      "14479             cant deal slow internet connection cant \n",
      "14480    mental health practitioner   coon rapids day t...\n",
      "14481    mental health practitioner   coon rapids day t...\n",
      "14482    mental health practitioner   coon rapids day t...\n",
      "14483    ben carson thinks okay confederate flag hangin...\n",
      "14484     \\n\\nkills captivity does\\ndeath  another \\nfo...\n",
      "14485                   diamond keep actin ima go job coon\n",
      "14486                            cries im turning weebcoon\n",
      "14487    saw gorgeous 4 12 year old maine coon today av...\n",
      "14488    jet stream maine coon riding last nightììåès s...\n",
      "14489                                    im even coon girl\n",
      "14490                         ive seen men women coon rate\n",
      "14491    bwtake care me pls buy coon ass somethin im br...\n",
      "14492    interesting data quantifying value internetnet...\n",
      "14493                                        thank youì«ìð\n",
      "14494                               aryan  say leave world\n",
      "14495                           sir aryan  ask leave india\n",
      "14496    radio nordfront interview russian patriot clas...\n",
      "14497    hope u check ur fb messages message requests a...\n",
      "14498    wowììa jewish man nose measured aryan race det...\n",
      "14499    oldpicsarchive jewish man nose measured aryan ...\n",
      "14500    jewish man nose measured aryan race determinat...\n",
      "14501    ao  aryan huy miss na happy ill able see tomor...\n",
      "14502                                   aryan version fifa\n",
      "14503    measured aryan race determination tests nazi g...\n",
      "14504    im sorry offend white supremacist aryan nation...\n",
      "14505    caucasian euro aryan whatever really matter th...\n",
      "14506    sir patient named aryan khan  village meeranpu...\n",
      "14507    happy birthday bro ì«ìð \\nhave happy year ahea...\n",
      "14508    aryan kapoor cute name tho  d want kamps first...\n",
      "Name: Tweets, Length: 14509, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(hate_speech_subset['Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       [warning penny boards make faggot]\n",
      "1                                             [fuck dykes]\n",
      "2               [least dont look like jefree starr faggot]\n",
      "3                           [   fag jackie jealous neeeee]\n",
      "4        [heard bitch way im back th texas wtf u talkin...\n",
      "5        [dirty terrorist religion fucking joke go arou...\n",
      "6                              [rt   looking like faggots]\n",
      "7        [well thought knew actually rt  man yall tell ...\n",
      "8                                       [know joke faggot]\n",
      "9        [im tired people saying look like brother amp ...\n",
      "10       [ yeah cuz 8 million people faggot ass   jewsg...\n",
      "11          [word use roids stupid hypocrite lying faggot]\n",
      "12                                     [hate faggots like]\n",
      "13       [shut nigger whore hope u get raped one animal...\n",
      "14       [fuck nigger sheboon hope r strung like nigger...\n",
      "15       [used tie ends niggers legs 2 different horses...\n",
      "16       [good night fags fagettes thats female version...\n",
      "17       [cant stand crybaby ass nigga gonna act like b...\n",
      "18                                           [rt   nigger]\n",
      "19                  [ill fuck til love faggot  mike tyson]\n",
      "20       [whats problem u know jews control niggers rea...\n",
      "21                             [fucking hate niggers bruh]\n",
      "22        [rt  species birds known hold funerals deceased]\n",
      "23       [remember draft prom night dress zip bawling e...\n",
      "24       [damn eli thats ruff im even gonna trash talk ...\n",
      "25       [also happy armistice day anachronists\\n\\n hun...\n",
      "26       [friend suggested dress fairy halloween party ...\n",
      "27       [rt  apparently  means  anyone else always tho...\n",
      "28       [suspended day random lag spikes force close c...\n",
      "29       [ w moxy big comeback again major penalty kill...\n",
      "                               ...                        \n",
      "14479            [cant deal slow internet connection cant]\n",
      "14480    [mental health practitioner   coon rapids day ...\n",
      "14481    [mental health practitioner   coon rapids day ...\n",
      "14482    [mental health practitioner   coon rapids day ...\n",
      "14483    [ben carson thinks okay confederate flag hangi...\n",
      "14484    [ \\n\\nkills captivity does\\ndeath  another \\nf...\n",
      "14485                 [diamond keep actin ima go job coon]\n",
      "14486                          [cries im turning weebcoon]\n",
      "14487    [saw gorgeous 4 12 year old maine coon today a...\n",
      "14488    [jet stream maine coon riding last nightììåès ...\n",
      "14489                                  [im even coon girl]\n",
      "14490                       [ive seen men women coon rate]\n",
      "14491    [bwtake care me pls buy coon ass somethin im b...\n",
      "14492    [interesting data quantifying value internetne...\n",
      "14493                                      [thank youì«ìð]\n",
      "14494                             [aryan  say leave world]\n",
      "14495                         [sir aryan  ask leave india]\n",
      "14496    [radio nordfront interview russian patriot cla...\n",
      "14497    [hope u check ur fb messages message requests ...\n",
      "14498    [wowììa jewish man nose measured aryan race de...\n",
      "14499    [oldpicsarchive jewish man nose measured aryan...\n",
      "14500    [jewish man nose measured aryan race determina...\n",
      "14501    [ao  aryan huy miss na happy ill able see tomo...\n",
      "14502                                 [aryan version fifa]\n",
      "14503    [measured aryan race determination tests nazi ...\n",
      "14504    [im sorry offend white supremacist aryan natio...\n",
      "14505    [caucasian euro aryan whatever really matter t...\n",
      "14506    [sir patient named aryan khan  village meeranp...\n",
      "14507    [happy birthday bro ì«ìð \\nhave happy year ahe...\n",
      "14508    [aryan kapoor cute name tho  d want kamps firs...\n",
      "Name: Tweets_Sentences, Length: 14509, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Sentence Tokenization\n",
    "hate_speech_subset['Tweets_Sentences'] = hate_speech_subset['Tweets'].map(lambda x: sent_tokenize(x))\n",
    "print(hate_speech_subset['Tweets_Sentences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylKI5RaDN2OQ"
   },
   "source": [
    "For now I'm just going to use the tweets as a predictor and use the Confidence later on in another capacity. The lack of a code book really hurts here because it's not clear how the Confidence was determined given that the label was mostly likely a majority vote between three people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Tokenization\n",
    "def identify_tokens(hate_speech_subset):\n",
    "    text = hate_speech_subset['Tweets']\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # taken only words (not punctuation)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "hate_speech_subset['Tweets_Words'] = hate_speech_subset.apply(identify_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "def stem_list(hate_speech_subset):\n",
    "    my_list = hate_speech_subset['Tweets_Words']\n",
    "    stemmed_list = [stemming.stem(word) for word in my_list]\n",
    "    return (stemmed_list)\n",
    "\n",
    "hate_speech_subset['stemmed_words'] = hate_speech_subset.apply(stem_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                       [warn, penni, board, make, faggot]\n",
      "1                                             [fuck, dyke]\n",
      "2          [least, dont, look, like, jefre, starr, faggot]\n",
      "3                             [fag, jacki, jealou, neeeee]\n",
      "4        [heard, bitch, way, im, back, th, texa, wtf, u...\n",
      "5        [dirti, terrorist, religion, fuck, joke, go, a...\n",
      "6                                 [rt, look, like, faggot]\n",
      "7        [well, thought, knew, actual, rt, man, yall, t...\n",
      "8                                     [know, joke, faggot]\n",
      "9        [im, tire, peopl, say, look, like, brother, am...\n",
      "10       [yeah, cuz, million, peopl, faggot, ass, jewsg...\n",
      "11        [word, use, roid, stupid, hypocrit, lie, faggot]\n",
      "12                                    [hate, faggot, like]\n",
      "13       [shut, nigger, whore, hope, u, get, rape, one,...\n",
      "14       [fuck, nigger, sheboon, hope, r, strung, like,...\n",
      "15       [use, tie, end, nigger, leg, differ, hors, bea...\n",
      "16       [good, night, fag, fagett, that, femal, versio...\n",
      "17       [cant, stand, crybabi, ass, nigga, gon, na, ac...\n",
      "18                                            [rt, nigger]\n",
      "19             [ill, fuck, til, love, faggot, mike, tyson]\n",
      "20       [what, problem, u, know, jew, control, nigger,...\n",
      "21                              [fuck, hate, nigger, bruh]\n",
      "22           [rt, speci, bird, known, hold, funer, deceas]\n",
      "23       [rememb, draft, prom, night, dress, zip, bawl,...\n",
      "24       [damn, eli, that, ruff, im, even, gon, na, tra...\n",
      "25       [also, happi, armistic, day, anachronist, hun,...\n",
      "26       [friend, suggest, dress, fairi, halloween, par...\n",
      "27       [rt, appar, mean, anyon, els, alway, thought, ...\n",
      "28       [suspend, day, random, lag, spike, forc, close...\n",
      "29       [w, moxi, big, comeback, again, major, penalti...\n",
      "                               ...                        \n",
      "14479          [cant, deal, slow, internet, connect, cant]\n",
      "14480    [mental, health, practition, coon, rapid, day,...\n",
      "14481    [mental, health, practition, coon, rapid, day,...\n",
      "14482    [mental, health, practition, coon, rapid, day,...\n",
      "14483    [ben, carson, think, okay, confeder, flag, han...\n",
      "14484    [kill, captiv, doe, death, anoth, forget, not,...\n",
      "14485           [diamond, keep, actin, ima, go, job, coon]\n",
      "14486                            [cri, im, turn, weebcoon]\n",
      "14487    [saw, gorgeou, year, old, main, coon, today, a...\n",
      "14488    [jet, stream, main, coon, ride, last, nightììå...\n",
      "14489                               [im, even, coon, girl]\n",
      "14490                  [ive, seen, men, women, coon, rate]\n",
      "14491    [bwtake, care, me, pl, buy, coon, ass, somethi...\n",
      "14492    [interest, data, quantifi, valu, internetnet, ...\n",
      "14493                                    [thank, youì, ìð]\n",
      "14494                            [aryan, say, leav, world]\n",
      "14495                       [sir, aryan, ask, leav, india]\n",
      "14496    [radio, nordfront, interview, russian, patriot...\n",
      "14497    [hope, u, check, ur, fb, messag, messag, reque...\n",
      "14498    [wowììa, jewish, man, nose, measur, aryan, rac...\n",
      "14499    [oldpicsarch, jewish, man, nose, measur, aryan...\n",
      "14500    [jewish, man, nose, measur, aryan, race, deter...\n",
      "14501    [ao, aryan, huy, miss, na, happi, ill, abl, se...\n",
      "14502                               [aryan, version, fifa]\n",
      "14503    [measur, aryan, race, determin, test, nazi, ge...\n",
      "14504    [im, sorri, offend, white, supremacist, aryan,...\n",
      "14505    [caucasian, euro, aryan, whatev, realli, matte...\n",
      "14506    [sir, patient, name, aryan, khan, villag, meer...\n",
      "14507    [happi, birthday, bro, ì, ìð, have, happi, yea...\n",
      "14508    [aryan, kapoor, cute, name, tho, d, want, kamp...\n",
      "Name: stemmed_words, Length: 14509, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(hate_speech_subset['stemmed_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rejoin words\n",
    "\n",
    "def rejoin_words(hate_speech_subset):\n",
    "    my_list = hate_speech_subset['stemmed_words']\n",
    "    joined_words = ( \" \".join(my_list))\n",
    "    return joined_words\n",
    "\n",
    "hate_speech_subset['processed'] = hate_speech_subset.apply(rejoin_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "IcHs4EX_N2OS",
    "outputId": "acbcec22-f0f5-42d0-f24c-5e5f24e0978c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "text = hate_speech_subset['processed'].values\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 2))\n",
    "vectorizer.fit(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HkZaarOWN2OW"
   },
   "source": [
    "In theory using the TfidfVectorizer to transform the text into a matrix would be a better approach but it didn't in this case - believe me, I tried. I think it may be a length (of tweets in general) issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZdbsZMH-N2OY"
   },
   "source": [
    "<h3> Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqC3mxKCN2OZ"
   },
   "source": [
    "First the baseline accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "f9cL5P97N2Ob",
    "outputId": "7e19d44f-5582-45d8-bfe4-91f0d3944f6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.501344\n",
       "2    0.333310\n",
       "0    0.165346\n",
       "Name: Numeric_Verdict, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_speech_subset['Numeric_Verdict'].value_counts()/len(hate_speech_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-998d481e4f52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mtrain_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mX_train_word_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_averaging_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mX_test_word_average\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_averaging_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_tokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-998d481e4f52>\u001b[0m in \u001b[0;36mword_averaging_list\u001b[0;34m(wv, text_list)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m  \u001b[0mword_averaging_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_averaging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-998d481e4f52>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m  \u001b[0mword_averaging_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_averaging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext_list\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mw2v_tokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-998d481e4f52>\u001b[0m in \u001b[0;36mword_averaging\u001b[0;34m(wv, words)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute similarity with no input %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# FIXME: remove these examples in pre-processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "wv.init_sims(replace=True)\n",
    "\n",
    "from itertools import islice\n",
    "list(islice(wv.vocab, 13030, 13050))\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list ])\n",
    "\n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "train, test = train_test_split(hate_speech_subset, test_size=0.1, random_state = 42)\n",
    "\n",
    "test_tokenized = test.apply(lambda r: w2v_tokenize_text(r['processed']), axis=1).values\n",
    "train_tokenized = train.apply(lambda r: w2v_tokenize_text(r['processed']), axis=1).values\n",
    "\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = logreg.fit(X_train_word_average, train['Numeric_Verdict'])\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "print('Word2Vec Logistic Regression accuracy %s' % accuracy_score(y_pred, test.Numeric_Verdict))\n",
    "word2vec_accuracy = accuracy_score(y_pred, test.Numeric_Verdict)\n",
    "classification_report(y_pred, test.Numeric_Verdict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : 0.7401791867677464\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.24      0.34       249\n",
      "           1       0.79      0.98      0.88       733\n",
      "           2       0.67      0.62      0.65       469\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1451\n",
      "   macro avg       0.68      0.62      0.62      1451\n",
      "weighted avg       0.72      0.74      0.71      1451\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb : 0.7195037904893177\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.05      0.09       249\n",
      "           1       0.79      0.96      0.87       733\n",
      "           2       0.61      0.69      0.65       469\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      1451\n",
      "   macro avg       0.62      0.57      0.54      1451\n",
      "weighted avg       0.67      0.72      0.66      1451\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc : 0.7601654031702274\n",
      "\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.38      0.43       249\n",
      "           1       0.86      0.96      0.91       733\n",
      "           2       0.67      0.65      0.66       469\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1451\n",
      "   macro avg       0.68      0.66      0.67      1451\n",
      "weighted avg       0.74      0.76      0.75      1451\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#recall_score, precision_score, classification_report, f1_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "clfs = {\n",
    "        'lr': LogisticRegression(), \n",
    "        'mnb': MultinomialNB(), \n",
    "        'rfc': RandomForestClassifier(), \n",
    "        'svm': SVC(kernel = 'linear', probability = True),\n",
    "        'KNearest' :  KNeighborsClassifier(2),\n",
    "        'DecisionTree' :  DecisionTreeClassifier(max_depth=5),\n",
    "        'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "        'MLP' :  MLPClassifier(alpha=1, max_iter=1000)\n",
    "       }\n",
    "\n",
    "def test_clf(clf_dict, Xtrain, ytrain):\n",
    "    for clf_name, clf in clf_dict.items():\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        predicted = clf.predict(X_test)\n",
    "        print(clf_name,\":\",np.mean(predicted == y_test))\n",
    "        print()\n",
    "        print(\"Classification Report: \",classification_report(y_test, predicted))\n",
    "        print() \n",
    "        cm = confusion_matrix(y_test, predicted)\n",
    "        fig, ax = plot_confusion_matrix(conf_mat = cm)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        precision, recall, fscore, support = score(y_test, predicted,average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"Accuracy: \",accuracy_score(y_test, predicted))\n",
    "        #print('precision: {}'.format(precision))\n",
    "        #print('recall: {}'.format(recall))\n",
    "        #print('fscore: {}'.format(fscore))\n",
    "        #print('support: {}'.format(support))\n",
    "        \n",
    "test_clf(clfs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7732598208132323\n",
      "[[ 75  29 145]\n",
      " [  3 716  14]\n",
      " [ 61  77 331]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = SVC(kernel = 'linear', probability = True).fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(np.mean(predicted == y_test))\n",
    "print(confusion_matrix(y_test, predicted))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.30      0.39       249\n",
      "           1       0.87      0.98      0.92       733\n",
      "           2       0.68      0.71      0.69       469\n",
      "\n",
      "    accuracy                           0.77      1451\n",
      "   macro avg       0.70      0.66      0.67      1451\n",
      "weighted avg       0.75      0.77      0.75      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "report= classification_report(y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78300804 0.77909648 0.77747989 0.78245883 0.78399081]\n",
      "0.7812068086900595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores_rfc = cross_val_score(SVC(kernel = 'linear', probability = True),  X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "print(scores_rfc)\n",
    "print(np.mean(scores_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgIfHAMgN2Og"
   },
   "source": [
    "So the classification would be 50% accurate if the most frequent class was always chosen as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5YsS_iYQN2Oh",
    "outputId": "cb3e883f-737e-4141-ff74-ec05b51e0c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14509, 17138)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer01 = TfidfVectorizer()\n",
    "X = vectorizer.transform(text)\n",
    "#X = vectorizer01.fit_transform(text)\n",
    "y = hate_speech_subset['Numeric_Verdict'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDV2Y4crN2Om"
   },
   "source": [
    "Thats a pretty big sparse matrix. Unfortunately dimensionality reduction isn't an option due to its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jpBWsFd9N2On",
    "outputId": "d94bcd21-9c2a-441c-9231-6da69f8e55be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : 0.911956621634041\n",
      "mnb : 0.8576417608675673\n",
      "rfc : 0.9620439297858653\n",
      "svm : 0.9461446558220752\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5661fb0b478d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtest_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-5661fb0b478d>\u001b[0m in \u001b[0;36mtest_clf\u001b[0;34m(clf_dict, Xtrain, ytrain)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtest_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/sklearn/neighbors/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 **kwds))\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ball_tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m     \"\"\"\n\u001b[0;32m--> 808\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clfs = {'lr': LogisticRegression(), \n",
    "        'mnb': MultinomialNB(), \n",
    "        'rfc': RandomForestClassifier(), \n",
    "        'svm': SVC(kernel = 'linear', probability = True),\n",
    "        'KNearest' :  KNeighborsClassifier(2),\n",
    "        'DecisionTree' :  DecisionTreeClassifier(max_depth=5),\n",
    "        'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "        'MLP' :  MLPClassifier(alpha=1, max_iter=1000)}\n",
    "\n",
    "def test_clf(clf_dict, Xtrain, ytrain):\n",
    "    for clf_name, clf in clf_dict.items():\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        print(clf_name,':', clf.score(Xtrain, ytrain))\n",
    "        \n",
    "test_clf(clfs, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54EMgBelN2Os"
   },
   "source": [
    "The classifiers do pretty well with the Random Forest Classifier and the SVC with a linear kernel being the best. (I tried other kernels for the SVC and they didn't perform well.) These also have the most parameters to tune, so I'll stick with them in a bid to get even higher accuracy. Before I move on though, I want to look at the accuracy in a more nuanced way with the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FD55Gq6N2Os"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "cm = confusion_matrix(y_train, \n",
    "                      SVC(kernel = 'linear', probability = True).fit(X_train, y_train).predict(X_train))\n",
    "fig, ax = plot_confusion_matrix(conf_mat = cm)\n",
    "plt.show()\n",
    "\n",
    "#0 : The tweet contains hate speech\n",
    "#1 : The tweet is not offensive\n",
    "#2 : The tweet uses offensive language but not hate speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "99W8l1KjN2Ov"
   },
   "source": [
    "It's incredibly good at classifying non-offensive tweets, but less so with the category of utmost importance, hate speech. This is where the concepts of precision and recall enter the frame. The former is a measure of how well the classifier doesn't mislabel a class will recall measures how well it gets every label for the class. For those tweets that contain hate speech, the precision is around 93% while the recall is about 92%.\n",
    "\n",
    "In this case, the most pertinent metric comes down to what is more important: making sure that tweets without hate speech aren't misclassified or getting as much instances of hate speech being used as possible. It's a trade-off as concentrating on one negatively affects the other. \n",
    "\n",
    "For now I'm going to use the F1 score which is a combination of precision and recall. It also is about the same as the accuracy in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgRb8HGHN2Ov"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739913610881353"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train,\n",
    "         SVC(kernel = 'linear', probability = True).fit(X_train, y_train).predict(X_train), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOSGPk4CN2Oy"
   },
   "source": [
    "Hyperparameter tuning of the SVC is long. My setup is below. The cross validation ran to completion and did badly on average. I had to stop the grid search lest it continue until the end of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0DXdnz9N2Oz"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8ed0bc37087e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(SVC(kernel = 'linear', probability = True), X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0mwTDU2N2O2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "C_range = np.logspace(-2, 4, 5)\n",
    "gamma_range = np.logspace(-3, 3, 5)\n",
    "param_grid = dict(gamma = gamma_range, C = C_range)\n",
    "grid_svc = GridSearchCV(SVC(kernel = 'linear', probability = True), \n",
    "                        param_grid = param_grid, \n",
    "                        cv = 10, \n",
    "                        scoring = 'accuracy')\n",
    "grid_svc.fit(X_train, y_train)\n",
    "grid_svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYuTrs7vN2O4"
   },
   "source": [
    "Using cross validation with the Random Forest Classifier works much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6BCpQATN2O5"
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores_rfc = cross_val_score(RandomForestClassifier(), X_train, y_train, cv = 10, scoring = 'accuracy')\n",
    "print(scores_rfc)\n",
    "print(np.mean(scores_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJLf1SjPN2O8"
   },
   "source": [
    "It is clearly the better of the two models. The next step would be to do grid search to make the model even better, but that's something I have to return to. For now here's the skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-lllbeTN2O9"
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"n_estimators\": [10, 50, 100]\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "grid_svc = GridSearchCV(RandomForestClassifier(), \n",
    "                        param_grid = param_grid, \n",
    "                        cv = 10, \n",
    "                        scoring = 'accuracy')\n",
    "grid_svc.fit(X_train, y_train)\n",
    "grid_svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39JNVAEsN2O_"
   },
   "source": [
    "Even though it hasn't been optimized, I'm going to built an app to classify hate speech with this model. To end, let export the pickle objects I'll need for the app, and look at how the model performs on the test set and on a constructed tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gOs3eB6N2PA"
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(clf_rfc, open('classifier.pkl', 'wb'), protocol = 4)\n",
    "pickle.dump(stopwords.words('english'), open('stopwords.pkl', 'wb'), protocol = 4)\n",
    "pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'), protocol = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TjssKd4qN2PC"
   },
   "outputs": [],
   "source": [
    "clf_rfc = RandomForestClassifier()\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "clf_rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mjDvsv4N2PE"
   },
   "outputs": [],
   "source": [
    "def classify_tweet(tweet, clf):\n",
    "    tweet_to_clf = processTweet(tweet)\n",
    "    tweet_to_clf = vectorizer.transform([tweet_to_clf])\n",
    "    label = clf.predict(tweet_to_clf)[0]\n",
    "    confidence = max(clf.predict_proba(tweet_to_clf)[0])*100\n",
    "    return 'The model says: ' + le.inverse_transform(label) + ' with ' + str(round(confidence, 2)) + '% confidence.'\n",
    "\n",
    "tweet = 'I hate you all.'\n",
    "classify_tweet(tweet, clf_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onIqNK3kN2PG"
   },
   "source": [
    "I suppose it's right. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hate_speech_crowdflower.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
